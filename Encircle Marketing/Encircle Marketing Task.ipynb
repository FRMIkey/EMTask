{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4929ba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests \n",
    "import time\n",
    "import schedule\n",
    "\n",
    "def tyres():\n",
    "    url = 'https://www.national.co.uk/price-comparison' # set the target website\n",
    "    page = requests.get(url) #get connection request\n",
    "    \n",
    "    soup = BeautifulSoup(page.content, 'html.parser') # start of our soup\n",
    "\n",
    "    tbl = soup.find('table', {'class':'table table-striped table-bordered'}) # reaching target table\n",
    "\n",
    "    hdrs = []\n",
    "\n",
    "    #for loop below grabs table header names \n",
    "    for i in tbl.find_all('th'):\n",
    "        title = i.text.strip()\n",
    "        hdrs.append(title)\n",
    "    \n",
    "    df = pd.DataFrame(columns = hdrs)\n",
    "    \n",
    "    #for loop below fetches data from the table\n",
    "    for row in tbl.find_all('tr')[1:]:\n",
    "        data = row.find_all('td')\n",
    "        row_data = [td.text.strip() for td in data]\n",
    "        length = len(df)\n",
    "        df.loc[length] = row_data\n",
    "\n",
    "    #now we drop unnecessary columns\n",
    "    df = df.drop(['MY TYRES PRICE', 'KWIK FIT PRICE', 'ATS PRICE'], axis =1)\n",
    "\n",
    "    #removing any empty space from data\n",
    "    #split data from the first column into multiple columns and assign this to sep DF\n",
    "    df['PRODUCT DESCRIPTION'].str.strip()\n",
    "\n",
    "    sep = df['PRODUCT DESCRIPTION'].str.split(' ', expand=True)\n",
    "\n",
    "    #name the columns of a new DF\n",
    "    sep.columns = ['1','2','3','4','5','6','7']\n",
    "\n",
    "    #drop empty column and combine tyre pattern and size columns into one \n",
    "    sep.drop(['7'], axis=1)\n",
    "    sep['x'] = sep['2']+ ' '+sep['3']+' '+sep['4']\n",
    "\n",
    "    #from sep DF assign column 1 to a brand column in our main DF. Then repeat for pattern and size column\n",
    "    df['Brand'] = sep['1']\n",
    "    df['pattern & size'] = sep['x'] \n",
    "    df = df.drop(['PRODUCT DESCRIPTION'], axis=1) # drop unnecessary column\n",
    "    df['url'] = url #add a colum with a url of scraped website\n",
    "\n",
    "    csvFile = df.to_csv('newFile.csv', index=False) # write to csv\n",
    "    \n",
    "    return page, csvFile\n",
    "\n",
    "# code below schedules running the code at a certain time to avoid accidental DDOS\n",
    "schedule.every().day.at(\"12:00\").do(tyres)\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
